{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Akhilesh/Downloads/BoC/fraud detection/Dataset.csv\",encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_dependents']=data['num_dependents'].replace(['1'], 1)\n",
    "#data['num_dependents']=data['num_dependents'].replace(['02-01-1900'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_num = data.columns\n",
    "data[cols_num].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(data.columns):\n",
    "    \n",
    "    # get a list of unique values\n",
    "    n = data[c].unique()\n",
    "    \n",
    "    # if number of unique values is less than 30, print the values. Otherwise print the number of unique values\n",
    "    if len(n)<30:\n",
    "        print(c)\n",
    "        print(n)\n",
    "    else:\n",
    "        print(c + ': ' +str(len(n)) + ' unique values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = sns.countplot(x = 'over_draft', hue = 'class', data = data)\n",
    "\n",
    "sns.despine()\n",
    "plot1.figure.set_size_inches(8,6)\n",
    "plot1.legend(title = 'distribution of over_draft')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = sns.countplot(x = 'credit_history', hue = 'class', data = data)\n",
    "\n",
    "sns.despine()\n",
    "plot1.figure.set_size_inches(8,6)\n",
    "plot1.legend(title = 'distribution of over_draft')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_distribution(attr):\n",
    "    good_risk_df = data[data[\"class\"]==\"good\"]\n",
    "    bad_risk_df = data[data[\"class\"]==\"bad\"]\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "    attr_good_risk_df = good_risk_df[[attr, 'class']].groupby(attr).count()\n",
    "    attr_bad_risk_df = bad_risk_df[[attr, 'class']].groupby(attr).count()\n",
    "    ax[0].barh( attr_good_risk_df['class'].index.tolist(), attr_good_risk_df['class'].tolist(), align='center', color=\"#5975A4\")\n",
    "    ax[1].barh( attr_bad_risk_df['class'].index.tolist(), attr_bad_risk_df['class'].tolist(), align='center', color=\"#B55D60\")\n",
    "    ax[0].set_title('Good Risk')\n",
    "    ax[1].set_title('Bad Risk')\n",
    "    ax[0].invert_xaxis()\n",
    "    ax[1].yaxis.tick_right()\n",
    "    \n",
    "    num_para_change=[\"residence_since\",\"existing_credits\",\"location\",\"num_dependents\"]\n",
    "    if attr in num_para_change:\n",
    "        for i, v in enumerate(attr_good_risk_df['class'].tolist()):\n",
    "            ax[0].text(v+15, i+1, str(v), color='black')\n",
    "        for i, v in enumerate(attr_bad_risk_df['class'].tolist()):\n",
    "            ax[1].text(v+2, i+1, str(v), color='black')\n",
    "    else:\n",
    "        for i, v in enumerate(attr_good_risk_df['class'].tolist()):\n",
    "            ax[0].text(v+25, i + .05, str(v), color='black')\n",
    "        for i, v in enumerate(attr_bad_risk_df['class'].tolist()):\n",
    "            ax[1].text(v+1, i + .05, str(v), color='black')\n",
    "    plt.suptitle(attr)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution('over_draft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution('credit_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution('purpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['purpose'].value_counts().plot('barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Item_plot = data['cc_age'].unique()\n",
    "\n",
    "Item_plot.sort()\n",
    "Item_sort = np.array(Item_plot).tolist()\n",
    "\n",
    "# paired bar plot to check b/w readmission within 30 days and age\n",
    "A1C = sns.countplot(x = 'cc_age', hue = 'class', data = data, order = Item_sort) \n",
    "\n",
    "sns.despine()\n",
    "A1C.figure.set_size_inches(20, 8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distribution('employment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = data.drop([\"current_balance\",\"cc_age\",\"credit_usage real\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "#from scipy import stats\n",
    "\n",
    "#from math import floor,ceil\n",
    "#import statsmodels.api as sm\n",
    "#import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,roc_curve\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
